{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4fb2f3-3c97-48bc-8af6-49fc1574416a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /tmp/ipykernel_144/3409415381.py:3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkConf, SparkContext\n\u001b[1;32m      2\u001b[0m conf \u001b[38;5;241m=\u001b[39m SparkConf()\u001b[38;5;241m.\u001b[39msetAppName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntro a DataFrames\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgetOrCreate(conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:198\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     )\n\u001b[0;32m--> 198\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    201\u001b[0m         master,\n\u001b[1;32m    202\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:445\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    442\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    450\u001b[0m             currentAppName,\n\u001b[1;32m    451\u001b[0m             currentMaster,\n\u001b[1;32m    452\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    453\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    454\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    455\u001b[0m         )\n\u001b[1;32m    456\u001b[0m     )\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /tmp/ipykernel_144/3409415381.py:3 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName('Intro a DataFrames')\n",
    "sc = SparkContext().getOrCreate(conf=conf)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "rdd = sc.textFile('people-100k.csv')\n",
    "headers = rdd.first()\n",
    "rdd = rdd.filter(lambda x: x != headers).map(lambda x: x.split(','))\n",
    "\n",
    "rdd_casted_types = rdd.map(lambda row: (int (row[0]), row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8]))\n",
    "\n",
    "columns = headers.split(',')\n",
    "df = rdd_casted_types.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bce492-726b-4911-86b4-eaf35adb7f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "|Index|Organization Id|                Name|             Website|             Country|         Description|Founded|            Industry|Number of employees|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "|    1|8cC6B5992C0309c|         Acevedo LLC|https://www.donov...|Holy See (Vatican...|Multi-channeled b...|   2019|Graphic Design / ...|               7070|\n",
      "|    2|ec094061FeaF7Bc|      Walls-Mcdonald|http://arias-will...|           Lithuania|Compatible encomp...|   2005|           Utilities|               8156|\n",
      "|    3|DAcC5dbc58946A7|         Gregory PLC|http://www.lynch-...|             Tokelau|Multi-channeled i...|   2019|    Leisure / Travel|               6121|\n",
      "|    4|8Dd7beDa37FbeD0|Byrd, Patterson a...|https://www.james...|         Netherlands|Pre-emptive natio...|   1982|           Furniture|               3494|\n",
      "|    5|a3b5c54AEC163e4|    Mcdowell-Hopkins| http://fuentes.com/|             Mayotte|Cloned bifurcated...|   2016|   Online Publishing|                 36|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.options(header='True',inferSchema='True').csv('people-100k.csv')\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9df396-7cb8-4ea0-9080-31676ca655d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Organization Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Website: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Founded: integer (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Number of employees: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9815d59-943a-4203-a492-100e934f462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                Name|             website|            Industry|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|         Acevedo LLC|https://www.donov...|Graphic Design / ...|\n",
      "|      Walls-Mcdonald|http://arias-will...|           Utilities|\n",
      "|         Gregory PLC|http://www.lynch-...|    Leisure / Travel|\n",
      "|Byrd, Patterson a...|https://www.james...|           Furniture|\n",
      "|    Mcdowell-Hopkins| http://fuentes.com/|   Online Publishing|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('Name','website','Industry').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e89bd2-eb14-4f84-bc4e-ce0eb344d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+\n",
      "|Index|         Description|Founded|\n",
      "+-----+--------------------+-------+\n",
      "|    1|Multi-channeled b...|   2019|\n",
      "|    2|Compatible encomp...|   2005|\n",
      "|    3|Multi-channeled i...|   2019|\n",
      "|    4|Pre-emptive natio...|   1982|\n",
      "|    5|Cloned bifurcated...|   2016|\n",
      "+-----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(df2.Index, df2.Description, df2.Founded).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc8a30f-31c3-42ac-9d78-83f6ec33deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|Index|Number of employees|\n",
      "+-----+-------------------+\n",
      "|    1|               7070|\n",
      "|    2|               8156|\n",
      "|    3|               6121|\n",
      "|    4|               3494|\n",
      "|    5|                 36|\n",
      "+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df2.select(col('Index'),col('Number of employees')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0474eb7d-e82c-40f1-bc0a-e0cdd09e5db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "|Index|Organization Id|                Name|             Website|             Country|         Description|Founded|            Industry|Number of employees|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "|    1|8cC6B5992C0309c|         Acevedo LLC|https://www.donov...|Holy See (Vatican...|Multi-channeled b...|   2019|Graphic Design / ...|               7070|\n",
      "|    2|ec094061FeaF7Bc|      Walls-Mcdonald|http://arias-will...|           Lithuania|Compatible encomp...|   2005|           Utilities|               8156|\n",
      "|    3|DAcC5dbc58946A7|         Gregory PLC|http://www.lynch-...|             Tokelau|Multi-channeled i...|   2019|    Leisure / Travel|               6121|\n",
      "|    4|8Dd7beDa37FbeD0|Byrd, Patterson a...|https://www.james...|         Netherlands|Pre-emptive natio...|   1982|           Furniture|               3494|\n",
      "|    5|a3b5c54AEC163e4|    Mcdowell-Hopkins| http://fuentes.com/|             Mayotte|Cloned bifurcated...|   2016|   Online Publishing|                 36|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e97a399e-7166-4f1d-a234-8edcfaa8a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------+\n",
      "|             Website|             Country|         Description|Founded|\n",
      "+--------------------+--------------------+--------------------+-------+\n",
      "|https://www.donov...|Holy See (Vatican...|Multi-channeled b...|   2019|\n",
      "|http://arias-will...|           Lithuania|Compatible encomp...|   2005|\n",
      "|http://www.lynch-...|             Tokelau|Multi-channeled i...|   2019|\n",
      "|https://www.james...|         Netherlands|Pre-emptive natio...|   1982|\n",
      "| http://fuentes.com/|             Mayotte|Cloned bifurcated...|   2016|\n",
      "+--------------------+--------------------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(df2.columns[3:7]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0b1e9-327f-4cf5-a659-00d80a0166bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
